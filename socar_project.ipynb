{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"socar_project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN+fgwTJI2a8rcGZ80SNmjX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"He1UQJsqU5FK","executionInfo":{"status":"ok","timestamp":1623688623295,"user_tz":-540,"elapsed":17387,"user":{"displayName":"‍이싸리스리솜분(대학원생-컴퓨터공학전공)","photoUrl":"","userId":"18207833417023329003"}},"outputId":"78edadae-9be6-40eb-efad-2033f3f9d894"},"source":["# mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h5mf1OJePJoI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623688631541,"user_tz":-540,"elapsed":4734,"user":{"displayName":"‍이싸리스리솜분(대학원생-컴퓨터공학전공)","photoUrl":"","userId":"18207833417023329003"}},"outputId":"24ee9dc2-7b11-4237-dec7-85d7fd210611"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os, sys\n","import numpy as np\n","import pandas as pd \n","from fnmatch import fnmatch\n","from tqdm import tqdm\n","import argparse\n","import time\n","import copy\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tRPx749jVX3B"},"source":["# preprocessing\n","root = '/content/drive/MyDrive/Colab Notebooks/쏘카/'\n","pattern = \"*-mp4-acc.csv\"\n","label = root + 'task1/data_set_01_labeling_result.csv'\n","\n","# label\n","df_label = pd.read_csv(label, encoding='cp949', index_col=False)\n","df_label = df_label.drop('Unnamed: 2', axis=1)\n","\n","# acc\n","acclists = []\n","for path, subdirs, files in os.walk(root + 'task1/'):\n","    for name in files:\n","        if fnmatch(name, pattern):\n","          acclists.append(os.path.join(path, name))\n","\n","files, x_list, y_list, z_list = [], [], [], []\n","\n","for acclist in acclists:\n","  file = acclist[76 : 105]\n","  file = file.replace('-', '.')\n","  files.append(file)\n","\n","  data_acc = pd.read_csv(acclist, index_col=False)\n","  x_list.append(data_acc.x.tolist()[1:])\n","  y_list.append(data_acc.y.tolist()[1:])\n","  z_list.append(data_acc.z.tolist()[1:])\n","\n","dict_x = {'file': files, 'x': x_list}\n","dict_y = {'file': files, 'x': y_list}\n","dict_z = {'file': files, 'x': z_list}\n","\n","df_x = pd.DataFrame(dict_x)\n","df_y = pd.DataFrame(dict_y)\n","df_z = pd.DataFrame(dict_z)\n","\n","df_x = pd.merge(df_x, df_label, how='inner', on=['file'])\n","df_y = pd.merge(df_y, df_label, how='inner', on=['file'])\n","df_z = pd.merge(df_z, df_label, how='inner', on=['file'])\n","\n","root_preproc = root + 'preprocessed/'\n","\n","df_x.to_csv(root_preproc + 'acc_x.csv', index=False)\n","df_y.to_csv(root_preproc + 'acc_y.csv', index=False) \n","df_z.to_csv(root_preproc + 'acc_z.csv', index=False) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTQizulOxxD-"},"source":["def preproc(data_path):\n","  data_csv = pd.read_csv(data_path, engine='python')\n","  labels_csv = [int(i) for i in data_csv['accident']]\n","  proc_data = []\n","  labels = []\n","\n","  idx = 0\n","\n","  for d in data_csv['x']:\n","    dat = d[1:-1].split(', ')\n","    dat = [float(x) for x in dat]\n","    if (len(dat) == 118):\n","      dat = torch.FloatTensor(dat)\n","      proc_data.append(dat)\n","      labels.append(labels_csv[idx])\n","    idx += 1\n","\n","  return proc_data, labels\n","\n","class CarDataloader(Dataset):\n","\n","  def __init__(self, transform=None):\n","    \"\"\"\n","    Args:\n","        csv_file (string): Path to the csv file with annotations.\n","        root_dir (string): Directory with all the images.\n","        transform (callable, optional): Optional transform to be applied\n","            on a sample.\n","    \"\"\"\n","    self.data_x, _  = preproc(root_preproc + 'acc_x.csv')\n","    self.data_y, _  = preproc(root_preproc + 'acc_y.csv')\n","    self.data_z, _  = preproc(root_preproc + 'acc_z.csv')\n","    _, self.labels = preproc(root_preproc + 'acc_x.csv')\n","      \n","  \n","  def get_num_of_classes(self):\n","    return 2\n","\n","  def __len__(self):\n","    return len(self.data_x)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","        idx = idx.tolist()\n","\n","    acc_x = self.data_x[idx]\n","    acc_y = self.data_y[idx]\n","    acc_z = self.data_z[idx]\n","    label = self.labels[idx]\n","\n","    data = torch.cat((acc_x, acc_y, acc_z))\n","    data = torch.reshape(data, (3,118))\n","\n","    return data, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GxdRLo6yJI8"},"source":["n_timesteps, n_features = 3, 118\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","hidden_size = 128\n","num_layers = 2\n","batch_size = 4\n","num_epochs = 100\n","learning_rate = 0.01\n","\n","input_size = 118\n","num_classes = 2\n","\n","car_dataloader = CarDataloader()\n","\n","torch.manual_seed(0)\n","torch.manual_seed(torch.initial_seed())\n","train_set, val_set = torch.utils.data.random_split(car_dataloader,\n","                                                   [int(0.7 * len(car_dataloader)), int(0.3 * len(car_dataloader))])\n","\n","train_dataloader = torch.utils.data.DataLoader(dataset=train_set,\n","                                               batch_size=batch_size,\n","                                               shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=val_set,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n","\n","# Recurrent neural network (many-to-one)\n","class RNN(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(RNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self, x):\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","    # Forward propagate LSTM\n","    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","\n","    # Decode the hidden state of the last time step\n","    out = self.fc(out[:, -1, :])\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kR78N1NE3n5C"},"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","\n","  def forward(self, x):\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","net = Net()\n","\n","class Net2(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","    self.PRelu = nn.PReLU()\n","\n","  def forward(self, x):\n","    x = self.PRelu(self.conv1(x))\n","    x = self.PRelu(self.conv2(x))\n","\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","\n","    x = self.PRelu(self.fc1(x))\n","    x = self.PRelu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","class Net3(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","    self.acc = nn.Tanh()\n","\n","  def forward(self, x):\n","    x = self.acc(self.conv1(x))\n","    x = self.acc(self.conv2(x))\n","\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","\n","    x = self.acc(self.fc1(x))\n","    x = self.acc(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","net = Net3()\n","\n","class Net23(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","    self.acc = nn.Tanh()\n","    self.acc2 = nn.PReLU()\n","\n","  def forward(self, input):\n","    x = self.acc(self.conv1(input))\n","    y = self.acc2(self.conv1(input))\n","\n","    x = torch.add(x, y)\n","\n","    y = self.acc2(self.conv2(x))\n","    x = self.acc(self.conv2(x))\n","\n","    x = torch.add(x, y)\n","\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","\n","    y = self.acc2(self.fc1(x))\n","    x = self.acc(self.fc1(x))\n","\n","    x = torch.add(x, y)\n","\n","    y = self.acc(self.fc2(x))\n","    x = self.acc(self.fc2(x))\n","\n","    x = torch.add(x, y)\n","    x = self.fc3(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-L3af_pq4GOX"},"source":["# Recurrent neural network (many-to-one)\n","class Combine(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(Combine, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","\n","  def forward(self, x):\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","    # Forward propagate LSTM\n","    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","\n","    # Decode the hidden state of the last time step\n","    out = self.fc(out[:, -1, :])\n","\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","\n","    out = torch.add(out, x)\n","\n","    return out\n","\n","# Recurrent neural network (many-to-one)\n","class Combine2(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","    super(Combine2, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    self.conv1 = nn.Conv1d(3, 3, 3)\n","    self.conv2 = nn.Conv1d(3, 6, 5)\n","    self.fc1 = nn.Linear(672, 128)\n","    self.fc2 = nn.Linear(128, 84)\n","    self.fc3 = nn.Linear(84, 2)\n","    self.PRelu = nn.PReLU()\n","\n","  def forward(self, x):\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","    # Forward propagate LSTM\n","    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","\n","    # Decode the hidden state of the last time step\n","    out = self.fc(out[:, -1, :])\n","\n","    x = self.PRelu(self.conv1(x))\n","    x = self.PRelu(self.conv2(x))\n","\n","    x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","\n","    x = self.PRelu(self.fc1(x))\n","    x = self.PRelu(self.fc2(x))\n","    x = self.fc3(x)\n","\n","    # out = F.relu(out)\n","    # x = F.relu(x)\n","\n","    out = torch.add(out, x)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_45Yn-n6HjQ"},"source":["# model = RNN(input_size, hidden_size, 4, num_classes).to(device)\n","# model = Net().to(device)\n","# model = Net2().to(device)\n","# model = Net3().to(device)\n","# model = Net23().to(device)\n","# model = Combine(input_size, hidden_size, num_layers, num_classes).to(device)\n","model = Combine2(input_size, hidden_size, num_layers, num_classes).to(device)\n","\n","# Load model\n","# root_model = root + 'models/'\n","\n","# model = torch.load(root_model + 'best_model_9583.pt')\n","# model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVRjCBELDYOQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623602992251,"user_tz":-540,"elapsed":11684,"user":{"displayName":"‍이싸리스리솜분(대학원생-컴퓨터공학전공)","photoUrl":"","userId":"18207833417023329003"}},"outputId":"410b528c-e0be-4531-accf-43157d96b854"},"source":["num_epochs = 100\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","train_total_step, test_total_step = len(train_dataloader), len(test_loader)\n","train_values, test_values = [], []\n","train_loss, test_loss = 0.0, 0.0\n","for epoch in range(num_epochs):\n","  for step, (acc_data, labels) in enumerate(train_dataloader):\n","    acc_data = acc_data.to(device)\n","    labels = labels.to(device)\n","\n","    # Forward pass\n","    outputs = model(acc_data)\n","    loss = criterion(outputs, labels)\n","\n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (step + 1) % (batch_size) == 0:\n","      # train_loss = loss.item() * acc_data.size(0)\n","      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","            .format(epoch + 1, num_epochs, step + 1, train_total_step, loss.item()))\n","\n","  # for step, (acc_data, labels) in enumerate(test_loader):\n","  #   acc_data = acc_data.to(device)\n","  #   labels = labels.to(device)\n","\n","  #   # Forward pass\n","  #   outputs = model(acc_data)\n","  #   loss = criterion(outputs, labels)\n","\n","  #   # Backward and optimize\n","  #   optimizer.zero_grad()\n","  #   loss.backward()\n","  #   optimizer.step()\n","\n","  #   if (step + 1) % (batch_size) == 0:\n","  #     test_loss = loss.item() * acc_data.size(0)\n","\n","  # train_values.append(train_loss / train_total_step)\n","  # test_values.append(test_loss / test_total_step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/100], Step [4/14], Loss: 2.1735\n","Epoch [1/100], Step [8/14], Loss: 0.5603\n","Epoch [1/100], Step [12/14], Loss: 0.6346\n","Epoch [2/100], Step [4/14], Loss: 0.5488\n","Epoch [2/100], Step [8/14], Loss: 0.6217\n","Epoch [2/100], Step [12/14], Loss: 0.7316\n","Epoch [3/100], Step [4/14], Loss: 0.1815\n","Epoch [3/100], Step [8/14], Loss: 0.8426\n","Epoch [3/100], Step [12/14], Loss: 0.2720\n","Epoch [4/100], Step [4/14], Loss: 0.1746\n","Epoch [4/100], Step [8/14], Loss: 0.0652\n","Epoch [4/100], Step [12/14], Loss: 0.0418\n","Epoch [5/100], Step [4/14], Loss: 0.0100\n","Epoch [5/100], Step [8/14], Loss: 0.0924\n","Epoch [5/100], Step [12/14], Loss: 0.0006\n","Epoch [6/100], Step [4/14], Loss: 0.0227\n","Epoch [6/100], Step [8/14], Loss: 0.0047\n","Epoch [6/100], Step [12/14], Loss: 0.0001\n","Epoch [7/100], Step [4/14], Loss: 0.0006\n","Epoch [7/100], Step [8/14], Loss: 0.0001\n","Epoch [7/100], Step [12/14], Loss: 0.0002\n","Epoch [8/100], Step [4/14], Loss: 0.0403\n","Epoch [8/100], Step [8/14], Loss: 0.0067\n","Epoch [8/100], Step [12/14], Loss: 0.0108\n","Epoch [9/100], Step [4/14], Loss: 0.1051\n","Epoch [9/100], Step [8/14], Loss: 0.0032\n","Epoch [9/100], Step [12/14], Loss: 0.0034\n","Epoch [10/100], Step [4/14], Loss: 0.0255\n","Epoch [10/100], Step [8/14], Loss: 0.0300\n","Epoch [10/100], Step [12/14], Loss: 0.0220\n","Epoch [11/100], Step [4/14], Loss: 0.1435\n","Epoch [11/100], Step [8/14], Loss: 0.0275\n","Epoch [11/100], Step [12/14], Loss: 0.0409\n","Epoch [12/100], Step [4/14], Loss: 0.0054\n","Epoch [12/100], Step [8/14], Loss: 0.0017\n","Epoch [12/100], Step [12/14], Loss: 0.0004\n","Epoch [13/100], Step [4/14], Loss: 0.0148\n","Epoch [13/100], Step [8/14], Loss: 0.0060\n","Epoch [13/100], Step [12/14], Loss: 0.0009\n","Epoch [14/100], Step [4/14], Loss: 0.0074\n","Epoch [14/100], Step [8/14], Loss: 0.0001\n","Epoch [14/100], Step [12/14], Loss: 0.0018\n","Epoch [15/100], Step [4/14], Loss: 0.0000\n","Epoch [15/100], Step [8/14], Loss: 0.0004\n","Epoch [15/100], Step [12/14], Loss: 0.0004\n","Epoch [16/100], Step [4/14], Loss: 0.0000\n","Epoch [16/100], Step [8/14], Loss: 0.0005\n","Epoch [16/100], Step [12/14], Loss: 0.0002\n","Epoch [17/100], Step [4/14], Loss: 0.0004\n","Epoch [17/100], Step [8/14], Loss: 0.0005\n","Epoch [17/100], Step [12/14], Loss: 0.0005\n","Epoch [18/100], Step [4/14], Loss: 0.0002\n","Epoch [18/100], Step [8/14], Loss: 0.0002\n","Epoch [18/100], Step [12/14], Loss: 0.0019\n","Epoch [19/100], Step [4/14], Loss: 0.0018\n","Epoch [19/100], Step [8/14], Loss: 0.0002\n","Epoch [19/100], Step [12/14], Loss: 0.0004\n","Epoch [20/100], Step [4/14], Loss: 0.0000\n","Epoch [20/100], Step [8/14], Loss: 0.0002\n","Epoch [20/100], Step [12/14], Loss: 0.0001\n","Epoch [21/100], Step [4/14], Loss: 0.0001\n","Epoch [21/100], Step [8/14], Loss: 0.0002\n","Epoch [21/100], Step [12/14], Loss: 0.0001\n","Epoch [22/100], Step [4/14], Loss: 0.0000\n","Epoch [22/100], Step [8/14], Loss: 0.0002\n","Epoch [22/100], Step [12/14], Loss: 0.0001\n","Epoch [23/100], Step [4/14], Loss: 0.0002\n","Epoch [23/100], Step [8/14], Loss: 0.0000\n","Epoch [23/100], Step [12/14], Loss: 0.0001\n","Epoch [24/100], Step [4/14], Loss: 0.0000\n","Epoch [24/100], Step [8/14], Loss: 0.0000\n","Epoch [24/100], Step [12/14], Loss: 0.0001\n","Epoch [25/100], Step [4/14], Loss: 0.0002\n","Epoch [25/100], Step [8/14], Loss: 0.0009\n","Epoch [25/100], Step [12/14], Loss: 0.0001\n","Epoch [26/100], Step [4/14], Loss: 0.0003\n","Epoch [26/100], Step [8/14], Loss: 0.0008\n","Epoch [26/100], Step [12/14], Loss: 0.0000\n","Epoch [27/100], Step [4/14], Loss: 0.0000\n","Epoch [27/100], Step [8/14], Loss: 0.0000\n","Epoch [27/100], Step [12/14], Loss: 0.0000\n","Epoch [28/100], Step [4/14], Loss: 0.0000\n","Epoch [28/100], Step [8/14], Loss: 0.0000\n","Epoch [28/100], Step [12/14], Loss: 0.0001\n","Epoch [29/100], Step [4/14], Loss: 0.0004\n","Epoch [29/100], Step [8/14], Loss: 0.0007\n","Epoch [29/100], Step [12/14], Loss: 0.0001\n","Epoch [30/100], Step [4/14], Loss: 0.0001\n","Epoch [30/100], Step [8/14], Loss: 0.0000\n","Epoch [30/100], Step [12/14], Loss: 0.0000\n","Epoch [31/100], Step [4/14], Loss: 0.0006\n","Epoch [31/100], Step [8/14], Loss: 0.0001\n","Epoch [31/100], Step [12/14], Loss: 0.0000\n","Epoch [32/100], Step [4/14], Loss: 0.0000\n","Epoch [32/100], Step [8/14], Loss: 0.0000\n","Epoch [32/100], Step [12/14], Loss: 0.0001\n","Epoch [33/100], Step [4/14], Loss: 0.0001\n","Epoch [33/100], Step [8/14], Loss: 0.0005\n","Epoch [33/100], Step [12/14], Loss: 0.0000\n","Epoch [34/100], Step [4/14], Loss: 0.0001\n","Epoch [34/100], Step [8/14], Loss: 0.0001\n","Epoch [34/100], Step [12/14], Loss: 0.0001\n","Epoch [35/100], Step [4/14], Loss: 0.0000\n","Epoch [35/100], Step [8/14], Loss: 0.0000\n","Epoch [35/100], Step [12/14], Loss: 0.0001\n","Epoch [36/100], Step [4/14], Loss: 0.0000\n","Epoch [36/100], Step [8/14], Loss: 0.0001\n","Epoch [36/100], Step [12/14], Loss: 0.0004\n","Epoch [37/100], Step [4/14], Loss: 0.0000\n","Epoch [37/100], Step [8/14], Loss: 0.0001\n","Epoch [37/100], Step [12/14], Loss: 0.0000\n","Epoch [38/100], Step [4/14], Loss: 0.0001\n","Epoch [38/100], Step [8/14], Loss: 0.0000\n","Epoch [38/100], Step [12/14], Loss: 0.0001\n","Epoch [39/100], Step [4/14], Loss: 0.0001\n","Epoch [39/100], Step [8/14], Loss: 0.0001\n","Epoch [39/100], Step [12/14], Loss: 0.0004\n","Epoch [40/100], Step [4/14], Loss: 0.0000\n","Epoch [40/100], Step [8/14], Loss: 0.0001\n","Epoch [40/100], Step [12/14], Loss: 0.0000\n","Epoch [41/100], Step [4/14], Loss: 0.0000\n","Epoch [41/100], Step [8/14], Loss: 0.0000\n","Epoch [41/100], Step [12/14], Loss: 0.0003\n","Epoch [42/100], Step [4/14], Loss: 0.0000\n","Epoch [42/100], Step [8/14], Loss: 0.0000\n","Epoch [42/100], Step [12/14], Loss: 0.0000\n","Epoch [43/100], Step [4/14], Loss: 0.0003\n","Epoch [43/100], Step [8/14], Loss: 0.0000\n","Epoch [43/100], Step [12/14], Loss: 0.0001\n","Epoch [44/100], Step [4/14], Loss: 0.0001\n","Epoch [44/100], Step [8/14], Loss: 0.0000\n","Epoch [44/100], Step [12/14], Loss: 0.0001\n","Epoch [45/100], Step [4/14], Loss: 0.0000\n","Epoch [45/100], Step [8/14], Loss: 0.0003\n","Epoch [45/100], Step [12/14], Loss: 0.0000\n","Epoch [46/100], Step [4/14], Loss: 0.0000\n","Epoch [46/100], Step [8/14], Loss: 0.0003\n","Epoch [46/100], Step [12/14], Loss: 0.0000\n","Epoch [47/100], Step [4/14], Loss: 0.0000\n","Epoch [47/100], Step [8/14], Loss: 0.0000\n","Epoch [47/100], Step [12/14], Loss: 0.0000\n","Epoch [48/100], Step [4/14], Loss: 0.0000\n","Epoch [48/100], Step [8/14], Loss: 0.0000\n","Epoch [48/100], Step [12/14], Loss: 0.0000\n","Epoch [49/100], Step [4/14], Loss: 0.0000\n","Epoch [49/100], Step [8/14], Loss: 0.0000\n","Epoch [49/100], Step [12/14], Loss: 0.0000\n","Epoch [50/100], Step [4/14], Loss: 0.0000\n","Epoch [50/100], Step [8/14], Loss: 0.0000\n","Epoch [50/100], Step [12/14], Loss: 0.0001\n","Epoch [51/100], Step [4/14], Loss: 0.0001\n","Epoch [51/100], Step [8/14], Loss: 0.0000\n","Epoch [51/100], Step [12/14], Loss: 0.0000\n","Epoch [52/100], Step [4/14], Loss: 0.0002\n","Epoch [52/100], Step [8/14], Loss: 0.0000\n","Epoch [52/100], Step [12/14], Loss: 0.0000\n","Epoch [53/100], Step [4/14], Loss: 0.0002\n","Epoch [53/100], Step [8/14], Loss: 0.0000\n","Epoch [53/100], Step [12/14], Loss: 0.0000\n","Epoch [54/100], Step [4/14], Loss: 0.0000\n","Epoch [54/100], Step [8/14], Loss: 0.0000\n","Epoch [54/100], Step [12/14], Loss: 0.0000\n","Epoch [55/100], Step [4/14], Loss: 0.0000\n","Epoch [55/100], Step [8/14], Loss: 0.0000\n","Epoch [55/100], Step [12/14], Loss: 0.0000\n","Epoch [56/100], Step [4/14], Loss: 0.0000\n","Epoch [56/100], Step [8/14], Loss: 0.0000\n","Epoch [56/100], Step [12/14], Loss: 0.0000\n","Epoch [57/100], Step [4/14], Loss: 0.0000\n","Epoch [57/100], Step [8/14], Loss: 0.0000\n","Epoch [57/100], Step [12/14], Loss: 0.0000\n","Epoch [58/100], Step [4/14], Loss: 0.0000\n","Epoch [58/100], Step [8/14], Loss: 0.0000\n","Epoch [58/100], Step [12/14], Loss: 0.0000\n","Epoch [59/100], Step [4/14], Loss: 0.0000\n","Epoch [59/100], Step [8/14], Loss: 0.0000\n","Epoch [59/100], Step [12/14], Loss: 0.0000\n","Epoch [60/100], Step [4/14], Loss: 0.0002\n","Epoch [60/100], Step [8/14], Loss: 0.0000\n","Epoch [60/100], Step [12/14], Loss: 0.0000\n","Epoch [61/100], Step [4/14], Loss: 0.0000\n","Epoch [61/100], Step [8/14], Loss: 0.0000\n","Epoch [61/100], Step [12/14], Loss: 0.0002\n","Epoch [62/100], Step [4/14], Loss: 0.0001\n","Epoch [62/100], Step [8/14], Loss: 0.0000\n","Epoch [62/100], Step [12/14], Loss: 0.0000\n","Epoch [63/100], Step [4/14], Loss: 0.0000\n","Epoch [63/100], Step [8/14], Loss: 0.0000\n","Epoch [63/100], Step [12/14], Loss: 0.0000\n","Epoch [64/100], Step [4/14], Loss: 0.0000\n","Epoch [64/100], Step [8/14], Loss: 0.0000\n","Epoch [64/100], Step [12/14], Loss: 0.0000\n","Epoch [65/100], Step [4/14], Loss: 0.0000\n","Epoch [65/100], Step [8/14], Loss: 0.0000\n","Epoch [65/100], Step [12/14], Loss: 0.0000\n","Epoch [66/100], Step [4/14], Loss: 0.0000\n","Epoch [66/100], Step [8/14], Loss: 0.0000\n","Epoch [66/100], Step [12/14], Loss: 0.0000\n","Epoch [67/100], Step [4/14], Loss: 0.0000\n","Epoch [67/100], Step [8/14], Loss: 0.0000\n","Epoch [67/100], Step [12/14], Loss: 0.0001\n","Epoch [68/100], Step [4/14], Loss: 0.0000\n","Epoch [68/100], Step [8/14], Loss: 0.0000\n","Epoch [68/100], Step [12/14], Loss: 0.0000\n","Epoch [69/100], Step [4/14], Loss: 0.0000\n","Epoch [69/100], Step [8/14], Loss: 0.0000\n","Epoch [69/100], Step [12/14], Loss: 0.0000\n","Epoch [70/100], Step [4/14], Loss: 0.0000\n","Epoch [70/100], Step [8/14], Loss: 0.0000\n","Epoch [70/100], Step [12/14], Loss: 0.0000\n","Epoch [71/100], Step [4/14], Loss: 0.0000\n","Epoch [71/100], Step [8/14], Loss: 0.0000\n","Epoch [71/100], Step [12/14], Loss: 0.0000\n","Epoch [72/100], Step [4/14], Loss: 0.0000\n","Epoch [72/100], Step [8/14], Loss: 0.0001\n","Epoch [72/100], Step [12/14], Loss: 0.0000\n","Epoch [73/100], Step [4/14], Loss: 0.0000\n","Epoch [73/100], Step [8/14], Loss: 0.0000\n","Epoch [73/100], Step [12/14], Loss: 0.0000\n","Epoch [74/100], Step [4/14], Loss: 0.0000\n","Epoch [74/100], Step [8/14], Loss: 0.0000\n","Epoch [74/100], Step [12/14], Loss: 0.0000\n","Epoch [75/100], Step [4/14], Loss: 0.0000\n","Epoch [75/100], Step [8/14], Loss: 0.0000\n","Epoch [75/100], Step [12/14], Loss: 0.0000\n","Epoch [76/100], Step [4/14], Loss: 0.0000\n","Epoch [76/100], Step [8/14], Loss: 0.0000\n","Epoch [76/100], Step [12/14], Loss: 0.0000\n","Epoch [77/100], Step [4/14], Loss: 0.0000\n","Epoch [77/100], Step [8/14], Loss: 0.0000\n","Epoch [77/100], Step [12/14], Loss: 0.0000\n","Epoch [78/100], Step [4/14], Loss: 0.0000\n","Epoch [78/100], Step [8/14], Loss: 0.0000\n","Epoch [78/100], Step [12/14], Loss: 0.0000\n","Epoch [79/100], Step [4/14], Loss: 0.0000\n","Epoch [79/100], Step [8/14], Loss: 0.0000\n","Epoch [79/100], Step [12/14], Loss: 0.0000\n","Epoch [80/100], Step [4/14], Loss: 0.0001\n","Epoch [80/100], Step [8/14], Loss: 0.0000\n","Epoch [80/100], Step [12/14], Loss: 0.0000\n","Epoch [81/100], Step [4/14], Loss: 0.0000\n","Epoch [81/100], Step [8/14], Loss: 0.0000\n","Epoch [81/100], Step [12/14], Loss: 0.0000\n","Epoch [82/100], Step [4/14], Loss: 0.0000\n","Epoch [82/100], Step [8/14], Loss: 0.0000\n","Epoch [82/100], Step [12/14], Loss: 0.0000\n","Epoch [83/100], Step [4/14], Loss: 0.0000\n","Epoch [83/100], Step [8/14], Loss: 0.0001\n","Epoch [83/100], Step [12/14], Loss: 0.0000\n","Epoch [84/100], Step [4/14], Loss: 0.0000\n","Epoch [84/100], Step [8/14], Loss: 0.0000\n","Epoch [84/100], Step [12/14], Loss: 0.0000\n","Epoch [85/100], Step [4/14], Loss: 0.0000\n","Epoch [85/100], Step [8/14], Loss: 0.0000\n","Epoch [85/100], Step [12/14], Loss: 0.0000\n","Epoch [86/100], Step [4/14], Loss: 0.0000\n","Epoch [86/100], Step [8/14], Loss: 0.0000\n","Epoch [86/100], Step [12/14], Loss: 0.0000\n","Epoch [87/100], Step [4/14], Loss: 0.0000\n","Epoch [87/100], Step [8/14], Loss: 0.0000\n","Epoch [87/100], Step [12/14], Loss: 0.0000\n","Epoch [88/100], Step [4/14], Loss: 0.0001\n","Epoch [88/100], Step [8/14], Loss: 0.0000\n","Epoch [88/100], Step [12/14], Loss: 0.0000\n","Epoch [89/100], Step [4/14], Loss: 0.0000\n","Epoch [89/100], Step [8/14], Loss: 0.0000\n","Epoch [89/100], Step [12/14], Loss: 0.0000\n","Epoch [90/100], Step [4/14], Loss: 0.0000\n","Epoch [90/100], Step [8/14], Loss: 0.0000\n","Epoch [90/100], Step [12/14], Loss: 0.0000\n","Epoch [91/100], Step [4/14], Loss: 0.0000\n","Epoch [91/100], Step [8/14], Loss: 0.0000\n","Epoch [91/100], Step [12/14], Loss: 0.0000\n","Epoch [92/100], Step [4/14], Loss: 0.0000\n","Epoch [92/100], Step [8/14], Loss: 0.0000\n","Epoch [92/100], Step [12/14], Loss: 0.0000\n","Epoch [93/100], Step [4/14], Loss: 0.0000\n","Epoch [93/100], Step [8/14], Loss: 0.0000\n","Epoch [93/100], Step [12/14], Loss: 0.0001\n","Epoch [94/100], Step [4/14], Loss: 0.0000\n","Epoch [94/100], Step [8/14], Loss: 0.0000\n","Epoch [94/100], Step [12/14], Loss: 0.0000\n","Epoch [95/100], Step [4/14], Loss: 0.0000\n","Epoch [95/100], Step [8/14], Loss: 0.0000\n","Epoch [95/100], Step [12/14], Loss: 0.0000\n","Epoch [96/100], Step [4/14], Loss: 0.0000\n","Epoch [96/100], Step [8/14], Loss: 0.0000\n","Epoch [96/100], Step [12/14], Loss: 0.0000\n","Epoch [97/100], Step [4/14], Loss: 0.0000\n","Epoch [97/100], Step [8/14], Loss: 0.0000\n","Epoch [97/100], Step [12/14], Loss: 0.0000\n","Epoch [98/100], Step [4/14], Loss: 0.0000\n","Epoch [98/100], Step [8/14], Loss: 0.0000\n","Epoch [98/100], Step [12/14], Loss: 0.0000\n","Epoch [99/100], Step [4/14], Loss: 0.0000\n","Epoch [99/100], Step [8/14], Loss: 0.0000\n","Epoch [99/100], Step [12/14], Loss: 0.0000\n","Epoch [100/100], Step [4/14], Loss: 0.0000\n","Epoch [100/100], Step [8/14], Loss: 0.0000\n","Epoch [100/100], Step [12/14], Loss: 0.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gPUg2gsVOD8I"},"source":["# plt.xlabel('epoch')\n","# plt.ylabel('loss')\n","# plt.plot(train_values, label='train')\n","# plt.plot(test_values, label='test')\n","# plt.legend()\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7p57Jfy9Dr5W","executionInfo":{"status":"ok","timestamp":1623602998631,"user_tz":-540,"elapsed":398,"user":{"displayName":"‍이싸리스리솜분(대학원생-컴퓨터공학전공)","photoUrl":"","userId":"18207833417023329003"}},"outputId":"5ecad695-b166-46fc-c4f7-bfc9a1c682b8"},"source":["# Test the model\n","model.eval()\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","  for acc_data, labels in test_loader:\n","      acc_data = acc_data.to(device)\n","      labels = labels.to(device)\n","      outputs = model(acc_data)\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","\n","  print('Test Accuracy : {} %'.format(100 * correct / total)) \n","\n","# Save the model checkpoint\n","# torch.save(model.state_dict(), root_model + 'model.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Accuracy : 45.833333333333336 %\n"],"name":"stdout"}]}]}